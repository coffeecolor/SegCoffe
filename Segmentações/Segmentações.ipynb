{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando imagem e transformando em cinza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Carregue a imagema partir do disco\n",
    "img = cv2.imread(\"cafe75.jpg\")\n",
    "# Converte a imagem para tons de cinza\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#imgdisplay = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#display(Image.fromarray(imgdisplay))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIMIARIZAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "   # Aplique a limiarização com o limiar de 64\n",
    "ret, img_threshold = cv2.threshold(img_gray, 130, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    #Testes para tirar fundo da segmentação\n",
    "inverted_mask = cv2.bitwise_not(img_threshold)\n",
    "\n",
    "    #cv2.imshow(\"Result\", inverted_mask)\n",
    "    # Aplicar máscara invertida à imagem original\n",
    "result = cv2.bitwise_and(img, img, mask=inverted_mask)\n",
    "\n",
    "    #   Adicionar um quarto canal (canal alpha) à imagem resultante\n",
    "result_with_alpha = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Definir a transparência para os pixels de fundo (onde a máscara binária é igual a 0)\n",
    "result_with_alpha[:, :, 3] = inverted_mask\n",
    "\n",
    "    # Salvar a imagem resultante com canal alpha em um arquivo PNG\n",
    "cv2.imwrite('imagem_com_alphaaa.png', result_with_alpha)\n",
    "\n",
    "    # Mostrar a imagem resultante com canal alpha\n",
    "cv2.imshow('Result', result_with_alpha)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECÇÃO DE BORDAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a imagem para escala de cinza\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplique o algoritmo Canny para detectar bordas\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "# Mostre a imagem original e a imagem com bordas detectadas\n",
    "cv2.imshow(\"Bordas\", edges)\n",
    "cv2.imwrite(\"Bordas.jpg\", edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MÉTODO PIRAMIDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aplique a transformada piramidal\n",
    "levels = 4\n",
    "pyramids = [img_gray]\n",
    "for i in range(levels):\n",
    "    pyramids.append(cv2.pyrDown(pyramids[i]))\n",
    "\n",
    "# Aplique o algoritmo de segmentação desejado (por exemplo, o's binarization)\n",
    "ret, thresh = cv2.threshold(pyramids[levels-1], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "# Expandir a segmentação para a imagem original\n",
    "for i in range(levels-1, 0, -1):\n",
    "    thresh = cv2.pyrUp(thresh)\n",
    "    thresh = cv2.resize(thresh, (pyramids[i].shape[1], pyramids[i].shape[0]))\n",
    "    #thresh = cv2.bitwise_and(pyramids[i], thresh)\n",
    "\n",
    "if thresh.shape != img.shape:\n",
    "    thresh = cv2.resize(thresh, (img.shape[1], img.shape[0]))\n",
    "\n",
    "if img.dtype != thresh.dtype:\n",
    "    img2 = cv2.convertTo(thresh, img.dtype)\n",
    "\n",
    "\n",
    "\n",
    "thresh = cv2.bitwise_and(img, img, mask=thresh)\n",
    "\n",
    "# Exibir a imagem segmentada\n",
    "cv2.imwrite(\"Piramidal-25-l4.jpg\", thresh)\n",
    "cv2.imshow(\"Segmentacao\", thresh)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGMENTAÇÃO NO ESPECTRO HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converte a imagem para o espectro HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# Defina os limites de tonalidade de cor (Hue) que deseja segmentar\n",
    "lower = np.array([10, 30, 30])\n",
    "upper = np.array([20, 255, 255])\n",
    "# Crie uma máscara utilizando os limites de tonalidade de cor\n",
    "mask = cv2.inRange(img_hsv, lower, upper)\n",
    "# Aplique a máscara na imagem original\n",
    "img_segmentada = cv2.bitwise_and(img, img, mask=mask)\n",
    "# Exiba o resultado da segmentação\n",
    "cv2.imshow(\"Segmentacao\", img_segmentada)\n",
    "cv2.imwrite(\"Método HSV graos75.png\", img_segmentada)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converte a imagem para o espectro HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# Defina os limites de tonalidade de cor (Hue) que deseja segmentar\n",
    "lower = np.array([0, 0, 10])\n",
    "upper = np.array([255, 255, 60])\n",
    "# Crie uma máscara utilizando os limites de tonalidade de cor\n",
    "mask = cv2.inRange(img_hsv, lower, upper)\n",
    "# Aplique a máscara na imagem original\n",
    "img_segmentada = cv2.bitwise_and(img, img, mask=mask)\n",
    "# Exiba o resultado da segmentação\n",
    "cv2.imshow(\"Segmentacao\", img_segmentada)\n",
    "cv2.imwrite(\"Método HSV graos.png\", img_segmentada)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "HSV COM A COR DO FUNDO\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converte a imagem para o espectro HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# Defina os limites de tonalidade de cor (Hue) que deseja segmentar\n",
    "lower = np.array([0, 0, 100])\n",
    "upper = np.array([180, 80, 255])\n",
    "# Crie uma máscara utilizando os limites de tonalidade de cor\n",
    "mask = cv2.inRange(img_hsv, lower, upper)\n",
    "mask = cv2.bitwise_not(mask)\n",
    "# Aplique a máscara na imagem original\n",
    "\n",
    "img_segmentada = cv2.bitwise_and(img, img, mask=mask)\n",
    "# Exiba o resultado da segmentação\n",
    "cv2.imshow(\"Segmentacao\", img_segmentada)\n",
    "cv2.imwrite(\"Método HSV 25.png\", img_segmentada)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A imagem é transformada em uma matriz unidimensional de dimensão 3, onde cada linha representa um pixel e cada coluna representa um canal de cor (vermelho, verde e azul).\n",
    "Z = img.reshape((-1,3))\n",
    "# converte para np.float32\n",
    "Z = np.float32(Z)\n",
    "# Defina as condições de parada do algoritmo K-Means\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "# Defina o número de grupos em que deseja dividir os pixels da imagem\n",
    "K = 2\n",
    "ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_PP_CENTERS)\n",
    "# converte de volta para uint8\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "res2 = res.reshape((img.shape))\n",
    "\n",
    "# Criar uma máscara com as áreas segmentadas em branco e o resto em preto\n",
    "mask = np.zeros((img.shape[0]*img.shape[1],1), np.uint8)\n",
    "majority_label = np.argmax(np.bincount(label.flatten()))\n",
    "mask[label.flatten() == majority_label] = 255\n",
    "mask = mask.reshape((img.shape[0],img.shape[1]))\n",
    "\n",
    "# Aplicar a máscara na imagem original\n",
    "inv_mask = cv2.bitwise_not(mask)\n",
    "result = cv2.bitwise_and(img, img, mask=inv_mask)\n",
    "\n",
    "\n",
    "    #   Adicionar um quarto canal (canal alpha) à imagem resultante\n",
    "result_with_alpha = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Definir a transparência para os pixels de fundo (onde a máscara binária é igual a 0)\n",
    "result_with_alpha[:, :, 3] = inv_mask\n",
    "\n",
    "\n",
    "    # Salvar a imagem resultante com canal alpha em um arquivo PNG\n",
    "cv2.imshow(\"Segmentacao\", result_with_alpha)\n",
    "cv2.imwrite('imagem_com_alphaaakmsssssssssssssssseans.png', result_with_alpha)\n",
    "\n",
    "# Mostrar o resultado\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECÇÃO DE BACIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ret, thresh = cv2.threshold(img_gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "# Remover os ruídos\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 3)\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=15)\n",
    "# Encontrar o marcador desconhecido e o marcador certo\n",
    "dist_transform = cv2.distanceTransform(opening, cv2.DIST_C, 3)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,1*dist_transform.max(),255,0)\n",
    "# encontrar marcador desconhecido\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "# Encontrar marcadores\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "# Adicione 1 a todos os marcadores para que os marcadores desconhecidos sejam 1, 2, 3, ...\n",
    "markers = markers+1\n",
    "# Marque o marcador desconhecido com 0\n",
    "markers[unknown == 255] = 0\n",
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "#cv2.imshow(\"Segmentacao\", unknown)\n",
    "#cv2.imshow(\"Segmentacao\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Testes para tirar fundo da segmentação\n",
    "# Inverter máscara de segmentação\n",
    "#inverted_mask = cv2.bitwise_not(segmentation_mask)\n",
    "\n",
    "# Aplicar máscara invertida à imagem original\n",
    "result = cv2.bitwise_and(img, img, mask=unknown)\n",
    "\n",
    "\n",
    "# Mostrar imagem resultante\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.imwrite(\"Deteccao de Bacias.jpg\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#Utilizando a função cv2.inpaint() para preencher as regiões do fundo da imagem com pixels interpolados.\n",
    "#inverted_mask = cv2.bitwise_not(unknown)\n",
    "#result2 = cv2.inpaint(img, inverted_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "# Mostrar imagem resultante\n",
    "#cv2.imshow(\"Result\", result2)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecção de Pontos\n",
    "ALGORITMO HARRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplique o detector de canto de Harris\n",
    "gray = np.float32(img_gray)\n",
    "dst = cv2.cornerHarris(img_gray, 4, 5, 0.02)\n",
    "\n",
    "# Normalize o resultado para torná-lo mais visível\n",
    "dst = cv2.dilate(dst, None)\n",
    "img[dst > 0.01*dst.max()] = [0, 0, 255]\n",
    "\n",
    "# Mostre a imagem com os pontos de canto\n",
    "cv2.imshow('image_with_points', img)\n",
    "cv2.imwrite(\"Deteccao de pontos harris.jpg\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um objeto FAST\n",
    "fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "# Detecte os pontos\n",
    "points = fast.detect(img_gray, None)\n",
    "\n",
    "# Desenhe os pontos na imagem\n",
    "image_with_points = cv2.drawKeypoints(img, points, outImage=None)\n",
    "\n",
    "# Mostre a imagem com os pontos\n",
    "cv2.imshow('image_with_points', image_with_points)\n",
    "cv2.imwrite(\"Deteccao de pontos fast.jpg\" , image_with_points)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Algoritmo ORB (Oriented FAST and Rotated BRIEF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um objeto ORB\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Detecte os pontos\n",
    "points = orb.detect(img_gray, None)\n",
    "\n",
    "# Calcule os descritores dos pontos\n",
    "points, descriptors = orb.compute(img_gray, points)\n",
    "\n",
    "# Desenhe os pontos na imagem\n",
    "image_with_points = cv2.drawKeypoints(img, points, outImage=None)\n",
    "\n",
    "# Mostre a imagem com os pontos\n",
    "cv2.imshow('image_with_points', image_with_points)\n",
    "cv2.imwrite(\"Deteccao de pontos orb.jpg\" , image_with_points)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DETECÇÃO DE LINHAS\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# Aplicar filtro de ruído gaussiano para suavizar a imagem\n",
    "gray_line = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "\n",
    "# Detectar as bordas da imagem usando o Canny Edge Detector\n",
    "edges = cv2.Canny(gray_line, 50, 150)\n",
    "\n",
    "# Executar a transformada de Hough para detectar as linhas\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=10, maxLineGap=50)\n",
    "\n",
    "# Desenhar as linhas detectadas na imagem de saída\n",
    "output_image = img.copy()\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(output_image, (x1, y1), (x2, y2), (0, 0, 256), 2)\n",
    "\n",
    "# Mostrar a imagem de saída\n",
    "cv2.imshow('Linhas detectadas', output_image)\n",
    "cv2.imwrite(\"Deteccao linhas.jpg\" , output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Crescimento de regioes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "imgcolorida = cv2.imread(\"cafe75.jpg\")\n",
    "\n",
    "def region_growing(img, seed):\n",
    "\n",
    "    output = np.zeros_like(img)\n",
    "\n",
    "    queue = []\n",
    "    queue.append(seed)\n",
    "\n",
    "    #define a tolerância de cor\n",
    "    tolerance = 70\n",
    "\n",
    "    # laço até que a fila esteja vazia\n",
    "    while len(queue) > 0:\n",
    "\n",
    "        pixel = queue.pop(0)\n",
    "\n",
    "        # checar se o pixel está dentro da imagem\n",
    "        if (pixel[0] >= 0 and pixel[0] < img.shape[0] and\n",
    "            pixel[1] >= 0 and pixel[1] < img.shape[1]):\n",
    "\n",
    "            # Checar se o pixel já foi processado\n",
    "            if output[pixel[0], pixel[1]] == 0:\n",
    "                # Check if the pixel is within the tolerance range of the seed pixel\n",
    "                if abs(int(img[pixel[0], pixel[1]]) - int(img[seed[0], seed[1]])) < tolerance:\n",
    "                    # Add the pixel to the region and mark it as processed\n",
    "                    output[pixel[0], pixel[1]] = 255\n",
    "\n",
    "                    # Add the neighboring pixels to the queue\n",
    "                    queue.append([pixel[0] - 1, pixel[1]])\n",
    "                    queue.append([pixel[0] + 1, pixel[1]])\n",
    "                    queue.append([pixel[0], pixel[1] - 1])\n",
    "                    queue.append([pixel[0], pixel[1] + 1])\n",
    "\n",
    "    #inverter saida\n",
    "    output = 255 - output\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# definir a função de callback do mouse\n",
    "def mouse_callback(event, x, y, flags, params):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Set the seed pixel location\n",
    "        params['seed'] = (y, x)\n",
    "\n",
    "\n",
    "img = cv2.imread('cafe75.jpg', 0)\n",
    "\n",
    "# criar uma janela para exibir a imagem\n",
    "cv2.namedWindow('Input')\n",
    "\n",
    "params = {'seed': None}\n",
    "cv2.setMouseCallback('Input', mouse_callback, params)\n",
    "\n",
    "\n",
    "cv2.imshow('Input', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# pegar a semente atraves do mouse\n",
    "seed = params['seed']\n",
    "\n",
    "#chamar a função de segmentação\n",
    "output = region_growing(img, seed)\n",
    "\n",
    "# Mostrar imagem resultante\n",
    "#cv2.imshow('Output', output)\n",
    "inverted_mask = cv2.bitwise_not(output)\n",
    "cv2.imshow(\"Result\", inverted_mask)\n",
    "result = cv2.bitwise_and(imgcolorida, imgcolorida, mask=inverted_mask)\n",
    "\n",
    "# Mostrar imagem resultante\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.imwrite(\"Crescimento75.jpg\", result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_growing(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    output = np.zeros_like(img_gray)\n",
    "\n",
    "    queue = []\n",
    "    seed = (img_gray.shape[0] // 2, img_gray.shape[1] // 2)\n",
    "    queue.append(seed)\n",
    "\n",
    "    # define a tolerância de cor\n",
    "    tolerance = 70\n",
    "\n",
    "    # laço até que a fila esteja vazia\n",
    "    while len(queue) > 0:\n",
    "        pixel = queue.pop(0)\n",
    "\n",
    "        # checar se o pixel está dentro da imagem\n",
    "        if (pixel[0] >= 0 and pixel[0] < img_gray.shape[0] and\n",
    "            pixel[1] >= 0 and pixel[1] < img_gray.shape[1]):\n",
    "            # Checar se o pixel já foi processado\n",
    "            if output[pixel[0], pixel[1]] == 0:\n",
    "                # Check if the pixel is within the tolerance range of the seed pixel\n",
    "                if abs(int(img_gray[pixel[0], pixel[1]]) - int(img_gray[seed[0], seed[1]])) < tolerance:\n",
    "                    # Add the pixel to the region and mark it as processed\n",
    "                    output[pixel[0], pixel[1]] = 255\n",
    "\n",
    "                    # Add the neighboring pixels to the queue\n",
    "                    queue.append([pixel[0] - 1, pixel[1]])\n",
    "                    queue.append([pixel[0] + 1, pixel[1]])\n",
    "                    queue.append([pixel[0], pixel[1] - 1])\n",
    "                    queue.append([pixel[0], pixel[1] + 1])\n",
    "\n",
    "    # inverter saida\n",
    "    output = 255 - output\n",
    "\n",
    "    inverted_mask = cv2.bitwise_not(output)\n",
    "    result = cv2.bitwise_and(img, img, mask=inverted_mask)\n",
    "\n",
    "    result_with_alpha = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "    result_with_alpha[:, :, 3] = inverted_mask\n",
    "    cv2.imwrite('imagem_com_alphaaa.png', result_with_alpha)\n",
    "\n",
    "    cv2.imshow(\"Result\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "img = cv2.imread(\"cafe75.jpg\")\n",
    "region_growing(img)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7004937324edf6fcbfde5b112033882932090ad78c6a35c51ac5cb91c6b60e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
